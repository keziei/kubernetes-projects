# Kezie Iroha
# -*- mode: ruby -*-
# vi: set ft=ruby :

Vagrant.configure("2") do |config|
  config.vm.box_check_update = false

  # Master node configuration
  config.vm.define "k8s-master" do |master|
    master.vm.box = "almalinux/9"
    master.vm.hostname = "k8s-master"
    master.vm.network "private_network", type: "dhcp"
    master.vm.provider "vmware_desktop" do |v|
      v.memory = 4096
      v.cpus = 2
    end

    master.vm.provision "shell", inline: <<-SHELL
      echo "Disabling swap..."
      swapoff -a
      sed -i '/swap/d' /etc/fstab

      echo "Enabling IP forwarding..."
      echo "net.ipv4.ip_forward = 1" > /etc/sysctl.d/99-k8s.conf
      sysctl --system

      echo "Installing dependencies..."
      dnf install -y epel-release yum-utils wget curl
      dnf config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo
      dnf install -y containerd.io

      echo "Configuring containerd..."
      mkdir -p /etc/containerd
      containerd config default > /etc/containerd/config.toml
      sed -i 's/SystemdCgroup = false/SystemdCgroup = true/' /etc/containerd/config.toml
      sed -i 's|registry.k8s.io/pause:3.8|registry.k8s.io/pause:3.10|g' /etc/containerd/config.toml
      systemctl restart containerd
      systemctl enable containerd --now

      echo "Loading required kernel modules..."
      cat <<EOF | tee /etc/modules-load.d/k8s.conf
overlay
br_netfilter
EOF
      modprobe overlay
      modprobe br_netfilter

      echo "Applying sysctl settings for Kubernetes..."
      cat <<EOF | tee /etc/sysctl.d/k8s.conf
net.bridge.bridge-nf-call-iptables  = 1
net.bridge.bridge-nf-call-ip6tables = 1
net.ipv4.ip_forward                 = 1
EOF
      sysctl --system

      echo "Adding Kubernetes repository..."
      # First, make sure any old repos are removed
      rm -f /etc/yum.repos.d/kubernetes.repo

      # Create the repository file
      cat <<EOF > /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=https://pkgs.k8s.io/core:/stable:/v1.32/rpm/
enabled=1
gpgcheck=1
gpgkey=https://pkgs.k8s.io/core:/stable:/v1.32/rpm/repodata/repomd.xml.key
EOF

      # Check if repo was created successfully
      if [ ! -f /etc/yum.repos.d/kubernetes.repo ]; then
        echo "ERROR: Failed to create Kubernetes repository file. Creating it again."
        cat <<EOF > /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=https://pkgs.k8s.io/core:/stable:/v1.32/rpm/
enabled=1
gpgcheck=1
gpgkey=https://pkgs.k8s.io/core:/stable:/v1.32/rpm/repodata/repomd.xml.key
EOF
      fi

      # Verify repository and clean cache
      dnf clean all
      dnf makecache

      echo "Installing Kubernetes components..."
      dnf install -y kubelet kubeadm kubectl
      
      # Verify installation was successful
      if ! command -v kubectl &> /dev/null; then
        echo "ERROR: kubectl installation failed. Trying alternative method."
        curl -LO "https://dl.k8s.io/release/v1.32.2/bin/linux/amd64/kubectl"
        chmod +x kubectl
        mv kubectl /usr/local/bin/
      fi
      
      # Check again and report result
      if command -v kubectl &> /dev/null; then
        echo "kubectl successfully installed at $(which kubectl)"
        kubectl version --client -o yaml
      else
        echo "FATAL: Failed to install kubectl! Cluster setup will likely fail."
      fi
      
      systemctl enable --now kubelet

      # Detect architecture and use appropriate CNI plugins
      ARCH=$(uname -m)
      echo "Detected architecture: $ARCH"

      echo "Installing CNI plugins for $ARCH architecture..."
      mkdir -p /opt/cni/bin
      
      if [ "$ARCH" == "aarch64" ] || [ "$ARCH" == "arm64" ]; then
        # ARM64 architecture
        wget https://github.com/containernetworking/plugins/releases/download/v1.3.0/cni-plugins-linux-arm64-v1.3.0.tgz -O cni-plugins.tgz
      else
        # Default to AMD64
        wget https://github.com/containernetworking/plugins/releases/download/v1.3.0/cni-plugins-linux-amd64-v1.3.0.tgz -O cni-plugins.tgz
      fi
      
      tar -C /opt/cni/bin -xzf cni-plugins.tgz
      rm -f cni-plugins.tgz

      echo "Pulling Kubernetes images..."
      kubeadm config images pull

      echo "Initializing Kubernetes cluster..."
      # Use pod CIDR 10.244.0.0/16 which is the default for Flannel
      kubeadm init --apiserver-advertise-address=$(hostname -I | awk '{print $2}') --pod-network-cidr=10.244.0.0/16

      echo "Setting up kubeconfig for vagrant user..."
      mkdir -p /home/vagrant/.kube
      cp -i /etc/kubernetes/admin.conf /home/vagrant/.kube/config
      chown -R vagrant:vagrant /home/vagrant/.kube

      echo "Deploying Flannel CNI..."
      kubectl --kubeconfig=/etc/kubernetes/admin.conf apply -f https://raw.githubusercontent.com/flannel-io/flannel/master/Documentation/kube-flannel.yml

      echo "Generating join command for worker nodes..."
      kubeadm token create --print-join-command > /vagrant/k8s-join-command.sh
      chmod +x /vagrant/k8s-join-command.sh
    SHELL

    # Separate provisioning step to copy admin.conf after it's created
    master.vm.provision "shell", inline: <<-SHELL
      echo "Copying admin.conf to /vagrant for worker nodes..."
      cp /etc/kubernetes/admin.conf /vagrant/admin.conf
      chmod 644 /vagrant/admin.conf
    SHELL
    
    # Add bash profile customizations using proper file creation
    master.vm.provision "shell", inline: <<-SHELL
      echo "Setting up bash profile customizations..."
      
      # Create bash profile for master node (control plane)
      cat > /root/.bash_profile << 'EOMASTER'
# Kubernetes aliases
alias k="kubectl"
alias kgp="kubectl get pods"
alias kgn="kubectl get nodes"
alias kgs="kubectl get services"
alias kgd="kubectl get deployments"
alias kdp="kubectl describe pod"
alias kdn="kubectl describe node"

# ETCD helpers
export ETCDCTL_API=3
alias etcdctl="kubectl -n kube-system exec -it etcd-k8s-master -- etcdctl --endpoints=https://127.0.0.1:2379 --cacert=/etc/kubernetes/pki/etcd/ca.crt --cert=/etc/kubernetes/pki/etcd/server.crt --key=/etc/kubernetes/pki/etcd/server.key"

# Bash completion for kubectl
source <(kubectl completion bash)
complete -F __start_kubectl k

# CKA exam shortcuts
alias kc="kubectl create -f"
alias kaf="kubectl apply -f"
alias keti="kubectl exec -ti"
alias kcns="kubectl create namespace"
alias kd="kubectl delete"
alias kgns="kubectl get namespaces"
alias kge="kubectl get events --sort-by=.metadata.creationTimestamp"

# Bash History settings
export HISTSIZE=10000
export HISTFILESIZE=20000
export HISTTIMEFORMAT="%d/%m/%y %T "

# System info on login
echo "-------------------------------------"
echo "Kubernetes Lab Environment - Control Plane"
echo "$(kubectl version --short 2>/dev/null || echo 'Run as root to see kubectl version')"
echo "-------------------------------------"

# Make sure kubectl is in the PATH
export PATH=$PATH:/usr/local/bin:/usr/bin
EOMASTER

      # Copy to vagrant user
      cp /root/.bash_profile /home/vagrant/.bash_profile
      chown vagrant:vagrant /home/vagrant/.bash_profile
      
      # Also add to .bashrc to ensure it works with non-login shells
      cp /root/.bash_profile /root/.bashrc
      cp /home/vagrant/.bash_profile /home/vagrant/.bashrc
      
      echo "Bash profiles have been set up on the master node."
    SHELL
  end

  # Worker nodes configuration
  ["k8s-worker1", "k8s-worker2"].each do |worker_name|
    config.vm.define worker_name do |worker|
      worker.vm.box = "almalinux/9"
      worker.vm.hostname = worker_name
      worker.vm.network "private_network", type: "dhcp"
      worker.vm.provider "vmware_desktop" do |v|
        v.memory = 4096
        v.cpus = 2
      end

      worker.vm.provision "shell", inline: <<-SHELL
        timeout=300
        elapsed=0
        while [ ! -f /vagrant/k8s-join-command.sh ]; do
          echo "Waiting for join command file..."
          sleep 10
          elapsed=$((elapsed + 10))
          if [ $elapsed -ge $timeout ]; then
            echo "ERROR: Timeout waiting for join command. Exiting."
            exit 1
          fi
        done
        echo "Join command found, proceeding with setup..."

        echo "Setting up repositories..."
        dnf install -y epel-release yum-utils wget curl
        dnf config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo
        
        echo "Adding Kubernetes repository..."
        # First, make sure any old repos are removed
        rm -f /etc/yum.repos.d/kubernetes.repo

        # Create the repository file
        cat <<EOF > /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=https://pkgs.k8s.io/core:/stable:/v1.32/rpm/
enabled=1
gpgcheck=1
gpgkey=https://pkgs.k8s.io/core:/stable:/v1.32/rpm/repodata/repomd.xml.key
EOF

        # Check if repo was created successfully
        if [ ! -f /etc/yum.repos.d/kubernetes.repo ]; then
          echo "ERROR: Failed to create Kubernetes repository file. Creating it again."
          cat <<EOF > /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=https://pkgs.k8s.io/core:/stable:/v1.32/rpm/
enabled=1
gpgcheck=1
gpgkey=https://pkgs.k8s.io/core:/stable:/v1.32/rpm/repodata/repomd.xml.key
EOF
        fi

        # Verify repository and clean cache
        dnf clean all
        dnf makecache
        
        echo "Installing containerd..."
        dnf install -y containerd.io
        
        echo "Configuring containerd..."
        mkdir -p /etc/containerd
        containerd config default > /etc/containerd/config.toml
        sed -i 's/SystemdCgroup = false/SystemdCgroup = true/' /etc/containerd/config.toml
        sed -i 's|registry.k8s.io/pause:3.8|registry.k8s.io/pause:3.10|g' /etc/containerd/config.toml
        systemctl restart containerd
        systemctl enable --now containerd

        echo "Loading kernel modules..."
        cat <<EOF | tee /etc/modules-load.d/k8s.conf
overlay
br_netfilter
EOF
        modprobe overlay
        modprobe br_netfilter

        echo "Enabling IP forwarding..."
        echo "net.ipv4.ip_forward = 1" > /etc/sysctl.d/99-k8s.conf
        cat <<EOF | tee /etc/sysctl.d/k8s.conf
net.bridge.bridge-nf-call-iptables  = 1
net.bridge.bridge-nf-call-ip6tables = 1
net.ipv4.ip_forward                 = 1
EOF
        sysctl --system

        echo "Disabling swap..."
        swapoff -a
        sed -i '/swap/d' /etc/fstab

        # Detect architecture and use appropriate CNI plugins
        ARCH=$(uname -m)
        echo "Detected architecture: $ARCH"

        echo "Installing CNI plugins for $ARCH architecture..."
        mkdir -p /opt/cni/bin
        
        if [ "$ARCH" == "aarch64" ] || [ "$ARCH" == "arm64" ]; then
          # ARM64 architecture
          wget https://github.com/containernetworking/plugins/releases/download/v1.3.0/cni-plugins-linux-arm64-v1.3.0.tgz -O cni-plugins.tgz
        else
          # Default to AMD64
          wget https://github.com/containernetworking/plugins/releases/download/v1.3.0/cni-plugins-linux-amd64-v1.3.0.tgz -O cni-plugins.tgz
        fi
        
        tar -C /opt/cni/bin -xzf cni-plugins.tgz
        rm -f cni-plugins.tgz

        echo "Installing Kubernetes components..."
        dnf install -y kubelet kubeadm kubectl
        
        # Verify installation was successful
        if ! command -v kubectl &> /dev/null; then
          echo "ERROR: kubectl installation failed. Trying alternative method."
          curl -LO "https://dl.k8s.io/release/v1.32.2/bin/linux/amd64/kubectl"
          chmod +x kubectl
          mv kubectl /usr/local/bin/
        fi
        
        # Check again and report result
        if command -v kubectl &> /dev/null; then
          echo "kubectl successfully installed at $(which kubectl)"
          kubectl version --client -o yaml
        else
          echo "FATAL: Failed to install kubectl! Node setup will continue but may have issues."
        fi
        
        systemctl enable --now kubelet

        echo "Joining Kubernetes cluster..."
        bash /vagrant/k8s-join-command.sh
      SHELL

      # Separate provisioning step to set up kubeconfig after joining the cluster
      worker.vm.provision "shell", inline: <<-SHELL
        echo "Waiting for admin.conf from master..."
        timeout=300
        elapsed=0
        while [ ! -f /vagrant/admin.conf ]; do
          echo "Waiting for /vagrant/admin.conf..."
          sleep 10
          elapsed=$((elapsed + 10))
          if [ $elapsed -ge $timeout ]; then
            echo "ERROR: Timeout waiting for /vagrant/admin.conf. Exiting."
            exit 1
          fi
        done
        echo "Copying admin.conf to both system and user locations..."
        # System location
        mkdir -p /etc/kubernetes
        cp /vagrant/admin.conf /etc/kubernetes/admin.conf
        chmod 644 /etc/kubernetes/admin.conf
        
        # User location (for convenience)
        mkdir -p /home/vagrant/.kube
        cp /vagrant/admin.conf /home/vagrant/.kube/config
        chown vagrant:vagrant /home/vagrant/.kube/config
        echo "export KUBECONFIG=/home/vagrant/.kube/config" >> /home/vagrant/.bashrc
      SHELL
      
      # Add bash profile customizations for worker nodes
      worker.vm.provision "shell", inline: <<-SHELL
        echo "Setting up bash profile customizations..."
        
        # Create bash profile for worker node
        cat > /root/.bash_profile << 'EOWORKER'
# Kubernetes aliases
alias k="kubectl"
alias kgp="kubectl get pods"
alias kgn="kubectl get nodes"
alias kgs="kubectl get services"
alias kgd="kubectl get deployments"
alias kdp="kubectl describe pod"
alias kdn="kubectl describe node"

# Bash completion for kubectl
source <(kubectl completion bash)
complete -F __start_kubectl k

# CKA exam shortcuts
alias kc="kubectl create -f"
alias kaf="kubectl apply -f"
alias keti="kubectl exec -ti"
alias kcns="kubectl create namespace"
alias kd="kubectl delete"
alias kgns="kubectl get namespaces"
alias kge="kubectl get events --sort-by=.metadata.creationTimestamp"

# Bash History settings
export HISTSIZE=10000
export HISTFILESIZE=20000
export HISTTIMEFORMAT="%d/%m/%y %T "

# System info on login
echo "-------------------------------------"
echo "Kubernetes Lab Environment - Worker Node"
echo "$(kubectl version --short 2>/dev/null || echo 'Run as root to see kubectl version')"
echo "-------------------------------------"

# Make sure kubectl is in the PATH
export PATH=$PATH:/usr/local/bin:/usr/bin
EOWORKER

        # Copy to vagrant user
        cp /root/.bash_profile /home/vagrant/.bash_profile
        chown vagrant:vagrant /home/vagrant/.bash_profile
        
        # Also add to .bashrc to ensure it works with non-login shells
        cp /root/.bash_profile /root/.bashrc
        cp /home/vagrant/.bash_profile /home/vagrant/.bashrc
        
        echo "Bash profiles have been set up on worker node $(hostname)."
      SHELL
    end
  end
end